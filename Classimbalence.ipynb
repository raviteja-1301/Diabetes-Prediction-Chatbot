{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "351fdf55-e364-4417-9fae-c6ef6241ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ready. CSV_PATH: diabetes_binary_health_indicators_BRFSS2015.csv\n"
     ]
    }
   ],
   "source": [
    "# Part 0: Shared config & imports (run this first)\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "CSV_PATH = \"diabetes_binary_health_indicators_BRFSS2015.csv\"\n",
    "OUTPUT_DIR = \"model_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# convenience: display full dataframe columns when needed\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"Config ready. CSV_PATH:\", CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f890cb2-893e-4844-8aba-bceec718f16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe shape: (253680, 22)\n",
      "\n",
      "Dtype summary (sample):\n",
      "uint8      21\n",
      "float32     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                0       1         1          1  40.0       1       0   \n",
       "1                0       0         0          0  25.0       1       0   \n",
       "2                0       1         1          1  28.0       0       0   \n",
       "3                0       1         0          1  27.0       0       0   \n",
       "4                0       1         1          1  24.0       0       0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                     0             0       0        1                  0   \n",
       "1                     0             1       0        0                  0   \n",
       "2                     0             0       1        0                  0   \n",
       "3                     0             1       1        1                  0   \n",
       "4                     0             1       1        1                  0   \n",
       "\n",
       "   AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  \\\n",
       "0              1            0        5        18        15         1    0   \n",
       "1              0            1        3         0         0         0    0   \n",
       "2              1            1        5        30        30         1    0   \n",
       "3              1            0        2         0         0         0    0   \n",
       "4              1            0        2         3         0         0    0   \n",
       "\n",
       "   Age  Education  Income  \n",
       "0    9          4       3  \n",
       "1    7          6       1  \n",
       "2    9          4       8  \n",
       "3   11          3       6  \n",
       "4   11          5       4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 1: Load & dtype optimization\n",
    "def load_and_optimize_dtypes(csv_path: str, use_sample=False, sample_frac=0.25):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if use_sample:\n",
    "        df = df.sample(frac=sample_frac, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "    # Example dtype downcasts (adjust to match your dataset columns)\n",
    "    binary_cols = [\n",
    "        \"HighBP\", \"HighChol\", \"CholCheck\", \"Smoker\", \"Stroke\", \"HeartDiseaseorAttack\",\n",
    "        \"PhysActivity\", \"Fruits\", \"Veggies\", \"HvyAlcoholConsump\", \"AnyHealthcare\",\n",
    "        \"NoDocbcCost\", \"DiffWalk\", \"Sex\"\n",
    "    ]\n",
    "    for c in binary_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], downcast=\"unsigned\")\n",
    "\n",
    "    if \"BMI\" in df.columns:\n",
    "        df[\"BMI\"] = pd.to_numeric(df[\"BMI\"], downcast=\"float\")\n",
    "    for c in [\"MentHlth\", \"PhysHlth\", \"GenHlth\", \"Age\", \"Education\", \"Income\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], downcast=\"unsigned\")\n",
    "\n",
    "    if \"Diabetes_binary\" in df.columns:\n",
    "        df[\"Diabetes_binary\"] = pd.to_numeric(df[\"Diabetes_binary\"], downcast=\"unsigned\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_and_optimize_dtypes(CSV_PATH, use_sample=False)\n",
    "print(\"Loaded dataframe shape:\", df.shape)\n",
    "print(\"\\nDtype summary (sample):\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df4fea7b-0156-49d1-acb7-188c7af26c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "Diabetes_binary\n",
      "0    218334\n",
      "1     35346\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target percentage positive:\n",
      "13.933301797540206\n",
      "\n",
      "Missing values per column (top 20):\n",
      "Diabetes_binary         0\n",
      "HighBP                  0\n",
      "Education               0\n",
      "Age                     0\n",
      "Sex                     0\n",
      "DiffWalk                0\n",
      "PhysHlth                0\n",
      "MentHlth                0\n",
      "GenHlth                 0\n",
      "NoDocbcCost             0\n",
      "AnyHealthcare           0\n",
      "HvyAlcoholConsump       0\n",
      "Veggies                 0\n",
      "Fruits                  0\n",
      "PhysActivity            0\n",
      "HeartDiseaseorAttack    0\n",
      "Stroke                  0\n",
      "Smoker                  0\n",
      "BMI                     0\n",
      "CholCheck               0\n",
      "dtype: int64\n",
      "\n",
      "Numeric summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>253680.0</td>\n",
       "      <td>28.382364</td>\n",
       "      <td>6.607666</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>253680.0</td>\n",
       "      <td>3.184772</td>\n",
       "      <td>7.412847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>253680.0</td>\n",
       "      <td>4.242081</td>\n",
       "      <td>8.717951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>253680.0</td>\n",
       "      <td>2.511392</td>\n",
       "      <td>1.068477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>253680.0</td>\n",
       "      <td>8.032119</td>\n",
       "      <td>3.054220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean       std   min   25%   50%   75%   max\n",
       "BMI       253680.0  28.382364  6.607666  12.0  24.0  27.0  31.0  98.0\n",
       "MentHlth  253680.0   3.184772  7.412847   0.0   0.0   0.0   2.0  30.0\n",
       "PhysHlth  253680.0   4.242081  8.717951   0.0   0.0   0.0   3.0  30.0\n",
       "GenHlth   253680.0   2.511392  1.068477   1.0   2.0   2.0   3.0   5.0\n",
       "Age       253680.0   8.032119  3.054220   1.0   6.0   8.0  10.0  13.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 2: Quick EDA\n",
    "target_col = \"Diabetes_binary\"\n",
    "assert target_col in df.columns, f\"Target '{target_col}' not found.\"\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(df[target_col].value_counts(dropna=False))\n",
    "print(\"\\nTarget percentage positive:\")\n",
    "print(df[target_col].mean() * 100)\n",
    "\n",
    "print(\"\\nMissing values per column (top 20):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "# A few summary stats for numeric columns\n",
    "num_cols = [\"BMI\", \"MentHlth\", \"PhysHlth\", \"GenHlth\", \"Age\"]\n",
    "num_cols = [c for c in num_cols if c in df.columns]\n",
    "if num_cols:\n",
    "    print(\"\\nNumeric summary:\")\n",
    "    display(df[num_cols].describe().T)\n",
    "else:\n",
    "    print(\"\\nNo numeric columns from the expected list were found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07b68d24-427c-412d-9193-2e2d7c20a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts: 21\n",
      "Numeric columns: ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
      "Binary / other columns (sample 20): ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex']\n"
     ]
    }
   ],
   "source": [
    "# Part 3: Prepare X and y, list numeric & binary cols\n",
    "target_col = \"Diabetes_binary\"\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "# Define numeric columns (continuous-ish)\n",
    "numeric_cols = [c for c in X.columns if c in {\"BMI\", \"MentHlth\", \"PhysHlth\", \"GenHlth\", \"Age\", \"Education\", \"Income\"}]\n",
    "binary_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "print(\"Feature counts:\", X.shape[1])\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Binary / other columns (sample 20):\", binary_cols[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5782019-e44b-446f-b5cf-ccb9a361a4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes -> Train: (171234, 21) Val: (19026, 21) Test: (63420, 21)\n",
      "Train positive rate: 0.13932980599647266 Test positive rate: 0.13934090192368337\n"
     ]
    }
   ],
   "source": [
    "# Part 4: Splits (75% train, 25% test; then val from train)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Now create a validation set from X_temp (10% of training)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.10, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Sizes -> Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "print(\"Train positive rate:\", y_train.mean(), \"Test positive rate:\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7505ad36-fa16-40ee-99cd-834e915b58d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor ready. Feature count after transform: 21\n"
     ]
    }
   ],
   "source": [
    "# Part 5: Build preprocessor and fit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def build_preprocessor(numeric_cols, binary_cols):\n",
    "    numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"bin\", \"passthrough\", binary_cols)\n",
    "    ], remainder=\"drop\")\n",
    "    return preprocessor\n",
    "\n",
    "preprocessor = build_preprocessor(numeric_cols, binary_cols)\n",
    "preprocessor.fit(X_train)  # fit only on train\n",
    "\n",
    "# Optionally sanity check\n",
    "_ = preprocessor.transform(X_train.iloc[:3])\n",
    "print(\"Preprocessor ready. Feature count after transform:\", preprocessor.transform(X_train[:1]).shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39fd1755-f62e-4379-a159-32e3ba7331ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6: Resampling libs + helpers\n",
    "!pip install -q imbalanced-learn xgboost\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Four class imbalance strategies\n",
    "samplers = {\n",
    "    \"SMOTE\": SMOTE(random_state=RANDOM_STATE),\n",
    "    \"ADASYN\": ADASYN(random_state=RANDOM_STATE),\n",
    "    \"SMOTE+Tomek\": SMOTETomek(random_state=RANDOM_STATE),\n",
    "    \"SMOTE+ENN\": SMOTEENN(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# We'll also include a \"None\" option to compare against no-resampling baseline\n",
    "samplers_with_none = {\"None\": None, **samplers}\n",
    "\n",
    "def pick_best_threshold(y_true_val, proba_val):\n",
    "    \"\"\"Pick threshold maximizing F1 on validation set (uses probabilities of positive class).\"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_val, proba_val)\n",
    "    # precision_recall_curve returns thresholds of length n-1\n",
    "    f1s = (2 * precisions[:-1] * recalls[:-1]) / (precisions[:-1] + recalls[:-1] + 1e-12)\n",
    "    best_idx = np.argmax(f1s)\n",
    "    best_thr = thresholds[best_idx]\n",
    "    return float(best_thr), float(f1s[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b9b7c21-9d33-4476-a7da-ae2e63b88c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 7: Model builders\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "def build_model(name: str):\n",
    "    if name == \"LogisticRegression\":\n",
    "        return LogisticRegression(\n",
    "            solver=\"saga\", penalty=\"l2\", max_iter=2000,\n",
    "            class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1\n",
    "        )\n",
    "    if name == \"DecisionTree\":\n",
    "        return DecisionTreeClassifier(\n",
    "            max_depth=None, min_samples_split=10, min_samples_leaf=5,\n",
    "            class_weight=\"balanced\", random_state=RANDOM_STATE\n",
    "        )\n",
    "    if name == \"RandomForest\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=300, max_depth=None, min_samples_split=10, min_samples_leaf=5,\n",
    "            class_weight=\"balanced_subsample\", n_jobs=-1, random_state=RANDOM_STATE\n",
    "        )\n",
    "    if name == \"KNN\":\n",
    "        # KNN is sensitive to scaling; preprocessor handles it\n",
    "        return KNeighborsClassifier(n_neighbors=31, weights=\"distance\", metric=\"minkowski\")\n",
    "    if name == \"XGBoost\":\n",
    "        # use scale_pos_weight to address imbalance\n",
    "        pos = np.sum(y_train == 1); neg = np.sum(y_train == 0)\n",
    "        spw = max(1.0, neg / max(1.0, pos))\n",
    "        return XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            n_estimators=800, learning_rate=0.05,\n",
    "            max_depth=6, subsample=0.8, colsample_bytree=0.8,\n",
    "            reg_alpha=0.1, reg_lambda=0.5,\n",
    "            tree_method=\"hist\",\n",
    "            eval_metric=\"auc\",\n",
    "            random_state=RANDOM_STATE,\n",
    "            scale_pos_weight=spw,\n",
    "            n_jobs=1\n",
    "        )\n",
    "    if name == \"LightGBM\":\n",
    "        pos = np.sum(y_train == 1); neg = np.sum(y_train == 0)\n",
    "        spw = max(1.0, neg / max(1.0, pos))\n",
    "        return lgb.LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            boosting_type=\"gbdt\",\n",
    "            n_estimators=1200,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            max_depth=7,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=1,\n",
    "            scale_pos_weight=spw\n",
    "        )\n",
    "    raise ValueError(f\"Unknown model name: {name}\")\n",
    "\n",
    "model_names = [\n",
    "    \"LogisticRegression\",\n",
    "    \"DecisionTree\",\n",
    "    \"RandomForest\",\n",
    "    \"KNN\",\n",
    "    \"XGBoost\",\n",
    "    \"LightGBM\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7711df2-decd-4648-a341-66e5445a8e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resampling: None ===\n",
      "[LogisticRegression | None] -> {'model': 'LogisticRegression', 'sampler': 'None', 'thr_val_best_f1': 0.6482, 'val_best_f1': 0.4672, 'test_accuracy': 0.8081, 'test_precision': 0.3771, 'test_recall': 0.5794, 'test_f1': 0.4569, 'test_roc_auc': 0.8219, 'test_pr_auc': 0.3972}\n",
      "[DecisionTree | None] -> {'model': 'DecisionTree', 'sampler': 'None', 'thr_val_best_f1': 0.607, 'val_best_f1': 0.3663, 'test_accuracy': 0.74, 'test_precision': 0.2772, 'test_recall': 0.5386, 'test_f1': 0.366, 'test_roc_auc': 0.6901, 'test_pr_auc': 0.2777}\n",
      "[RandomForest | None] -> {'model': 'RandomForest', 'sampler': 'None', 'thr_val_best_f1': 0.5571, 'val_best_f1': 0.4693, 'test_accuracy': 0.8224, 'test_precision': 0.3994, 'test_recall': 0.5444, 'test_f1': 0.4608, 'test_roc_auc': 0.8235, 'test_pr_auc': 0.4174}\n",
      "[KNN | None] -> {'model': 'KNN', 'sampler': 'None', 'thr_val_best_f1': 0.2281, 'val_best_f1': 0.4473, 'test_accuracy': 0.7917, 'test_precision': 0.3552, 'test_recall': 0.6071, 'test_f1': 0.4481, 'test_roc_auc': 0.7961, 'test_pr_auc': 0.3676}\n",
      "[XGBoost | None] -> {'model': 'XGBoost', 'sampler': 'None', 'thr_val_best_f1': 0.6408, 'val_best_f1': 0.4697, 'test_accuracy': 0.8089, 'test_precision': 0.3814, 'test_recall': 0.5976, 'test_f1': 0.4657, 'test_roc_auc': 0.8246, 'test_pr_auc': 0.419}\n",
      "[LightGBM] [Info] Number of positive: 23858, number of negative: 147376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 203\n",
      "[LightGBM] [Info] Number of data points in the train set: 171234, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.139330 -> initscore=-1.820868\n",
      "[LightGBM] [Info] Start training from score -1.820868\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM | None] -> {'model': 'LightGBM', 'sampler': 'None', 'thr_val_best_f1': 0.6759, 'val_best_f1': 0.4759, 'test_accuracy': 0.8236, 'test_precision': 0.403, 'test_recall': 0.5522, 'test_f1': 0.4659, 'test_roc_auc': 0.8254, 'test_pr_auc': 0.4197}\n",
      "\n",
      "=== Resampling: SMOTE ===\n",
      "[LogisticRegression | SMOTE] -> {'model': 'LogisticRegression', 'sampler': 'SMOTE', 'thr_val_best_f1': 0.6019, 'val_best_f1': 0.4663, 'test_accuracy': 0.7864, 'test_precision': 0.3539, 'test_recall': 0.6457, 'test_f1': 0.4572, 'test_roc_auc': 0.8199, 'test_pr_auc': 0.3938}\n",
      "[DecisionTree | SMOTE] -> {'model': 'DecisionTree', 'sampler': 'SMOTE', 'thr_val_best_f1': 0.1429, 'val_best_f1': 0.3684, 'test_accuracy': 0.6962, 'test_precision': 0.2565, 'test_recall': 0.6215, 'test_f1': 0.3631, 'test_roc_auc': 0.6876, 'test_pr_auc': 0.2622}\n",
      "[RandomForest | SMOTE] -> {'model': 'RandomForest', 'sampler': 'SMOTE', 'thr_val_best_f1': 0.3549, 'val_best_f1': 0.4622, 'test_accuracy': 0.7937, 'test_precision': 0.3604, 'test_recall': 0.62, 'test_f1': 0.4558, 'test_roc_auc': 0.8187, 'test_pr_auc': 0.403}\n",
      "[KNN | SMOTE] -> {'model': 'KNN', 'sampler': 'SMOTE', 'thr_val_best_f1': 0.6561, 'val_best_f1': 0.4351, 'test_accuracy': 0.7748, 'test_precision': 0.3317, 'test_recall': 0.6078, 'test_f1': 0.4292, 'test_roc_auc': 0.7876, 'test_pr_auc': 0.3469}\n",
      "[XGBoost | SMOTE] -> {'model': 'XGBoost', 'sampler': 'SMOTE', 'thr_val_best_f1': 0.6575, 'val_best_f1': 0.4729, 'test_accuracy': 0.8047, 'test_precision': 0.3762, 'test_recall': 0.6094, 'test_f1': 0.4652, 'test_roc_auc': 0.826, 'test_pr_auc': 0.4213}\n",
      "[LightGBM] [Info] Number of positive: 147376, number of negative: 147376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5355\n",
      "[LightGBM] [Info] Number of data points in the train set: 294752, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM | SMOTE] -> {'model': 'LightGBM', 'sampler': 'SMOTE', 'thr_val_best_f1': 0.6516, 'val_best_f1': 0.4736, 'test_accuracy': 0.808, 'test_precision': 0.3803, 'test_recall': 0.6, 'test_f1': 0.4655, 'test_roc_auc': 0.8252, 'test_pr_auc': 0.419}\n",
      "\n",
      "=== Resampling: ADASYN ===\n",
      "[LogisticRegression | ADASYN] -> {'model': 'LogisticRegression', 'sampler': 'ADASYN', 'thr_val_best_f1': 0.6447, 'val_best_f1': 0.4652, 'test_accuracy': 0.7992, 'test_precision': 0.3658, 'test_recall': 0.601, 'test_f1': 0.4548, 'test_roc_auc': 0.8188, 'test_pr_auc': 0.3915}\n",
      "[DecisionTree | ADASYN] -> {'model': 'DecisionTree', 'sampler': 'ADASYN', 'thr_val_best_f1': 0.2287, 'val_best_f1': 0.3579, 'test_accuracy': 0.7528, 'test_precision': 0.2835, 'test_recall': 0.5068, 'test_f1': 0.3636, 'test_roc_auc': 0.6895, 'test_pr_auc': 0.262}\n",
      "[RandomForest | ADASYN] -> {'model': 'RandomForest', 'sampler': 'ADASYN', 'thr_val_best_f1': 0.3298, 'val_best_f1': 0.4612, 'test_accuracy': 0.7713, 'test_precision': 0.3386, 'test_recall': 0.6727, 'test_f1': 0.4504, 'test_roc_auc': 0.8172, 'test_pr_auc': 0.3972}\n",
      "[KNN | ADASYN] -> {'model': 'KNN', 'sampler': 'ADASYN', 'thr_val_best_f1': 0.6609, 'val_best_f1': 0.4273, 'test_accuracy': 0.7678, 'test_precision': 0.3242, 'test_recall': 0.6142, 'test_f1': 0.4244, 'test_roc_auc': 0.7815, 'test_pr_auc': 0.332}\n",
      "[XGBoost | ADASYN] -> {'model': 'XGBoost', 'sampler': 'ADASYN', 'thr_val_best_f1': 0.6604, 'val_best_f1': 0.4728, 'test_accuracy': 0.8074, 'test_precision': 0.3805, 'test_recall': 0.6082, 'test_f1': 0.4682, 'test_roc_auc': 0.8261, 'test_pr_auc': 0.4215}\n",
      "[LightGBM] [Info] Number of positive: 141978, number of negative: 147376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5355\n",
      "[LightGBM] [Info] Number of data points in the train set: 289354, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.490672 -> initscore=-0.037315\n",
      "[LightGBM] [Info] Start training from score -0.037315\n",
      "[LightGBM | ADASYN] -> {'model': 'LightGBM', 'sampler': 'ADASYN', 'thr_val_best_f1': 0.6392, 'val_best_f1': 0.4728, 'test_accuracy': 0.8031, 'test_precision': 0.3745, 'test_recall': 0.6165, 'test_f1': 0.4659, 'test_roc_auc': 0.8248, 'test_pr_auc': 0.4177}\n",
      "\n",
      "=== Resampling: SMOTE+Tomek ===\n",
      "[LogisticRegression | SMOTE+Tomek] -> {'model': 'LogisticRegression', 'sampler': 'SMOTE+Tomek', 'thr_val_best_f1': 0.6559, 'val_best_f1': 0.4662, 'test_accuracy': 0.8083, 'test_precision': 0.3763, 'test_recall': 0.5712, 'test_f1': 0.4537, 'test_roc_auc': 0.8199, 'test_pr_auc': 0.3937}\n",
      "[DecisionTree | SMOTE+Tomek] -> {'model': 'DecisionTree', 'sampler': 'SMOTE+Tomek', 'thr_val_best_f1': 0.2, 'val_best_f1': 0.3719, 'test_accuracy': 0.727, 'test_precision': 0.2696, 'test_recall': 0.5613, 'test_f1': 0.3643, 'test_roc_auc': 0.6898, 'test_pr_auc': 0.2641}\n",
      "[RandomForest | SMOTE+Tomek] -> {'model': 'RandomForest', 'sampler': 'SMOTE+Tomek', 'thr_val_best_f1': 0.3392, 'val_best_f1': 0.461, 'test_accuracy': 0.7838, 'test_precision': 0.3506, 'test_recall': 0.6478, 'test_f1': 0.455, 'test_roc_auc': 0.8189, 'test_pr_auc': 0.402}\n",
      "[KNN | SMOTE+Tomek] -> {'model': 'KNN', 'sampler': 'SMOTE+Tomek', 'thr_val_best_f1': 0.6561, 'val_best_f1': 0.4352, 'test_accuracy': 0.7743, 'test_precision': 0.3318, 'test_recall': 0.6114, 'test_f1': 0.4301, 'test_roc_auc': 0.788, 'test_pr_auc': 0.3463}\n",
      "[XGBoost | SMOTE+Tomek] -> {'model': 'XGBoost', 'sampler': 'SMOTE+Tomek', 'thr_val_best_f1': 0.6608, 'val_best_f1': 0.4715, 'test_accuracy': 0.8056, 'test_precision': 0.3771, 'test_recall': 0.6063, 'test_f1': 0.465, 'test_roc_auc': 0.8259, 'test_pr_auc': 0.4218}\n",
      "[LightGBM] [Info] Number of positive: 146530, number of negative: 146530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5355\n",
      "[LightGBM] [Info] Number of data points in the train set: 293060, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM | SMOTE+Tomek] -> {'model': 'LightGBM', 'sampler': 'SMOTE+Tomek', 'thr_val_best_f1': 0.6522, 'val_best_f1': 0.4728, 'test_accuracy': 0.8078, 'test_precision': 0.38, 'test_recall': 0.6008, 'test_f1': 0.4655, 'test_roc_auc': 0.8247, 'test_pr_auc': 0.4176}\n",
      "\n",
      "=== Resampling: SMOTE+ENN ===\n",
      "[LogisticRegression | SMOTE+ENN] -> {'model': 'LogisticRegression', 'sampler': 'SMOTE+ENN', 'thr_val_best_f1': 0.7507, 'val_best_f1': 0.466, 'test_accuracy': 0.7863, 'test_precision': 0.3541, 'test_recall': 0.6469, 'test_f1': 0.4577, 'test_roc_auc': 0.8211, 'test_pr_auc': 0.3962}\n",
      "[DecisionTree | SMOTE+ENN] -> {'model': 'DecisionTree', 'sampler': 'SMOTE+ENN', 'thr_val_best_f1': 0.5925, 'val_best_f1': 0.4198, 'test_accuracy': 0.7923, 'test_precision': 0.3418, 'test_recall': 0.5302, 'test_f1': 0.4156, 'test_roc_auc': 0.7544, 'test_pr_auc': 0.3069}\n",
      "[RandomForest | SMOTE+ENN] -> {'model': 'RandomForest', 'sampler': 'SMOTE+ENN', 'thr_val_best_f1': 0.6426, 'val_best_f1': 0.4696, 'test_accuracy': 0.8186, 'test_precision': 0.3936, 'test_recall': 0.5578, 'test_f1': 0.4615, 'test_roc_auc': 0.8226, 'test_pr_auc': 0.4112}\n",
      "[KNN | SMOTE+ENN] -> {'model': 'KNN', 'sampler': 'SMOTE+ENN', 'thr_val_best_f1': 0.9029, 'val_best_f1': 0.4482, 'test_accuracy': 0.8074, 'test_precision': 0.3683, 'test_recall': 0.5345, 'test_f1': 0.4361, 'test_roc_auc': 0.7986, 'test_pr_auc': 0.3516}\n",
      "[XGBoost | SMOTE+ENN] -> {'model': 'XGBoost', 'sampler': 'SMOTE+ENN', 'thr_val_best_f1': 0.851, 'val_best_f1': 0.4711, 'test_accuracy': 0.808, 'test_precision': 0.3817, 'test_recall': 0.6098, 'test_f1': 0.4695, 'test_roc_auc': 0.8273, 'test_pr_auc': 0.4213}\n",
      "[LightGBM] [Info] Number of positive: 134291, number of negative: 97610\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5355\n",
      "[LightGBM] [Info] Number of data points in the train set: 231901, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.579088 -> initscore=0.319029\n",
      "[LightGBM] [Info] Start training from score 0.319029\n",
      "[LightGBM | SMOTE+ENN] -> {'model': 'LightGBM', 'sampler': 'SMOTE+ENN', 'thr_val_best_f1': 0.8478, 'val_best_f1': 0.4721, 'test_accuracy': 0.8092, 'test_precision': 0.383, 'test_recall': 0.6042, 'test_f1': 0.4688, 'test_roc_auc': 0.8267, 'test_pr_auc': 0.4207}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sampler</th>\n",
       "      <th>thr_val_best_f1</th>\n",
       "      <th>val_best_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>SMOTE+ENN</td>\n",
       "      <td>0.592454</td>\n",
       "      <td>0.419804</td>\n",
       "      <td>0.792274</td>\n",
       "      <td>0.341796</td>\n",
       "      <td>0.530157</td>\n",
       "      <td>0.415632</td>\n",
       "      <td>0.754353</td>\n",
       "      <td>0.306924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>None</td>\n",
       "      <td>0.606965</td>\n",
       "      <td>0.366291</td>\n",
       "      <td>0.740019</td>\n",
       "      <td>0.277212</td>\n",
       "      <td>0.538644</td>\n",
       "      <td>0.366041</td>\n",
       "      <td>0.690061</td>\n",
       "      <td>0.277718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>SMOTE+Tomek</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.371906</td>\n",
       "      <td>0.727026</td>\n",
       "      <td>0.269638</td>\n",
       "      <td>0.561276</td>\n",
       "      <td>0.364277</td>\n",
       "      <td>0.689833</td>\n",
       "      <td>0.264081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.228739</td>\n",
       "      <td>0.357883</td>\n",
       "      <td>0.752807</td>\n",
       "      <td>0.283517</td>\n",
       "      <td>0.506846</td>\n",
       "      <td>0.363629</td>\n",
       "      <td>0.689505</td>\n",
       "      <td>0.261961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.368357</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>0.256468</td>\n",
       "      <td>0.621478</td>\n",
       "      <td>0.363095</td>\n",
       "      <td>0.687640</td>\n",
       "      <td>0.262230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.228102</td>\n",
       "      <td>0.447317</td>\n",
       "      <td>0.791659</td>\n",
       "      <td>0.355157</td>\n",
       "      <td>0.607106</td>\n",
       "      <td>0.448148</td>\n",
       "      <td>0.796122</td>\n",
       "      <td>0.367560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SMOTE+ENN</td>\n",
       "      <td>0.902855</td>\n",
       "      <td>0.448180</td>\n",
       "      <td>0.807379</td>\n",
       "      <td>0.368265</td>\n",
       "      <td>0.534457</td>\n",
       "      <td>0.436063</td>\n",
       "      <td>0.798622</td>\n",
       "      <td>0.351569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SMOTE+Tomek</td>\n",
       "      <td>0.656117</td>\n",
       "      <td>0.435235</td>\n",
       "      <td>0.774267</td>\n",
       "      <td>0.331778</td>\n",
       "      <td>0.611407</td>\n",
       "      <td>0.430141</td>\n",
       "      <td>0.787954</td>\n",
       "      <td>0.346280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.656117</td>\n",
       "      <td>0.435062</td>\n",
       "      <td>0.774756</td>\n",
       "      <td>0.331748</td>\n",
       "      <td>0.607785</td>\n",
       "      <td>0.429216</td>\n",
       "      <td>0.787572</td>\n",
       "      <td>0.346943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.660950</td>\n",
       "      <td>0.427319</td>\n",
       "      <td>0.767849</td>\n",
       "      <td>0.324215</td>\n",
       "      <td>0.614236</td>\n",
       "      <td>0.424411</td>\n",
       "      <td>0.781491</td>\n",
       "      <td>0.332017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SMOTE+ENN</td>\n",
       "      <td>0.847768</td>\n",
       "      <td>0.472066</td>\n",
       "      <td>0.809240</td>\n",
       "      <td>0.383026</td>\n",
       "      <td>0.604164</td>\n",
       "      <td>0.468827</td>\n",
       "      <td>0.826735</td>\n",
       "      <td>0.420708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.639176</td>\n",
       "      <td>0.472758</td>\n",
       "      <td>0.803075</td>\n",
       "      <td>0.374484</td>\n",
       "      <td>0.616499</td>\n",
       "      <td>0.465940</td>\n",
       "      <td>0.824849</td>\n",
       "      <td>0.417737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.675850</td>\n",
       "      <td>0.475905</td>\n",
       "      <td>0.823605</td>\n",
       "      <td>0.402973</td>\n",
       "      <td>0.552224</td>\n",
       "      <td>0.465938</td>\n",
       "      <td>0.825446</td>\n",
       "      <td>0.419683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SMOTE+Tomek</td>\n",
       "      <td>0.652206</td>\n",
       "      <td>0.472812</td>\n",
       "      <td>0.807774</td>\n",
       "      <td>0.379974</td>\n",
       "      <td>0.600769</td>\n",
       "      <td>0.465518</td>\n",
       "      <td>0.824698</td>\n",
       "      <td>0.417571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.651644</td>\n",
       "      <td>0.473577</td>\n",
       "      <td>0.808026</td>\n",
       "      <td>0.380290</td>\n",
       "      <td>0.599977</td>\n",
       "      <td>0.465516</td>\n",
       "      <td>0.825197</td>\n",
       "      <td>0.419025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE+ENN</td>\n",
       "      <td>0.750699</td>\n",
       "      <td>0.465986</td>\n",
       "      <td>0.786345</td>\n",
       "      <td>0.354060</td>\n",
       "      <td>0.646939</td>\n",
       "      <td>0.457653</td>\n",
       "      <td>0.821106</td>\n",
       "      <td>0.396192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.601893</td>\n",
       "      <td>0.466313</td>\n",
       "      <td>0.786392</td>\n",
       "      <td>0.353926</td>\n",
       "      <td>0.645694</td>\n",
       "      <td>0.457230</td>\n",
       "      <td>0.819894</td>\n",
       "      <td>0.393761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.648248</td>\n",
       "      <td>0.467168</td>\n",
       "      <td>0.808057</td>\n",
       "      <td>0.377136</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.456878</td>\n",
       "      <td>0.821924</td>\n",
       "      <td>0.397214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.644663</td>\n",
       "      <td>0.465215</td>\n",
       "      <td>0.799243</td>\n",
       "      <td>0.365847</td>\n",
       "      <td>0.600996</td>\n",
       "      <td>0.454826</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.391504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE+Tomek</td>\n",
       "      <td>0.655944</td>\n",
       "      <td>0.466219</td>\n",
       "      <td>0.808310</td>\n",
       "      <td>0.376267</td>\n",
       "      <td>0.571235</td>\n",
       "      <td>0.453692</td>\n",
       "      <td>0.819870</td>\n",
       "      <td>0.393728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model      sampler  thr_val_best_f1  val_best_f1  \\\n",
       "0         DecisionTree    SMOTE+ENN         0.592454     0.419804   \n",
       "1         DecisionTree         None         0.606965     0.366291   \n",
       "2         DecisionTree  SMOTE+Tomek         0.200000     0.371906   \n",
       "3         DecisionTree       ADASYN         0.228739     0.357883   \n",
       "4         DecisionTree        SMOTE         0.142857     0.368357   \n",
       "5                  KNN         None         0.228102     0.447317   \n",
       "6                  KNN    SMOTE+ENN         0.902855     0.448180   \n",
       "7                  KNN  SMOTE+Tomek         0.656117     0.435235   \n",
       "8                  KNN        SMOTE         0.656117     0.435062   \n",
       "9                  KNN       ADASYN         0.660950     0.427319   \n",
       "10            LightGBM    SMOTE+ENN         0.847768     0.472066   \n",
       "11            LightGBM       ADASYN         0.639176     0.472758   \n",
       "12            LightGBM         None         0.675850     0.475905   \n",
       "13            LightGBM  SMOTE+Tomek         0.652206     0.472812   \n",
       "14            LightGBM        SMOTE         0.651644     0.473577   \n",
       "15  LogisticRegression    SMOTE+ENN         0.750699     0.465986   \n",
       "16  LogisticRegression        SMOTE         0.601893     0.466313   \n",
       "17  LogisticRegression         None         0.648248     0.467168   \n",
       "18  LogisticRegression       ADASYN         0.644663     0.465215   \n",
       "19  LogisticRegression  SMOTE+Tomek         0.655944     0.466219   \n",
       "\n",
       "    test_accuracy  test_precision  test_recall   test_f1  test_roc_auc  \\\n",
       "0        0.792274        0.341796     0.530157  0.415632      0.754353   \n",
       "1        0.740019        0.277212     0.538644  0.366041      0.690061   \n",
       "2        0.727026        0.269638     0.561276  0.364277      0.689833   \n",
       "3        0.752807        0.283517     0.506846  0.363629      0.689505   \n",
       "4        0.696200        0.256468     0.621478  0.363095      0.687640   \n",
       "5        0.791659        0.355157     0.607106  0.448148      0.796122   \n",
       "6        0.807379        0.368265     0.534457  0.436063      0.798622   \n",
       "7        0.774267        0.331778     0.611407  0.430141      0.787954   \n",
       "8        0.774756        0.331748     0.607785  0.429216      0.787572   \n",
       "9        0.767849        0.324215     0.614236  0.424411      0.781491   \n",
       "10       0.809240        0.383026     0.604164  0.468827      0.826735   \n",
       "11       0.803075        0.374484     0.616499  0.465940      0.824849   \n",
       "12       0.823605        0.402973     0.552224  0.465938      0.825446   \n",
       "13       0.807774        0.379974     0.600769  0.465518      0.824698   \n",
       "14       0.808026        0.380290     0.599977  0.465516      0.825197   \n",
       "15       0.786345        0.354060     0.646939  0.457653      0.821106   \n",
       "16       0.786392        0.353926     0.645694  0.457230      0.819894   \n",
       "17       0.808057        0.377136     0.579382  0.456878      0.821924   \n",
       "18       0.799243        0.365847     0.600996  0.454826      0.818828   \n",
       "19       0.808310        0.376267     0.571235  0.453692      0.819870   \n",
       "\n",
       "    test_pr_auc  \n",
       "0      0.306924  \n",
       "1      0.277718  \n",
       "2      0.264081  \n",
       "3      0.261961  \n",
       "4      0.262230  \n",
       "5      0.367560  \n",
       "6      0.351569  \n",
       "7      0.346280  \n",
       "8      0.346943  \n",
       "9      0.332017  \n",
       "10     0.420708  \n",
       "11     0.417737  \n",
       "12     0.419683  \n",
       "13     0.417571  \n",
       "14     0.419025  \n",
       "15     0.396192  \n",
       "16     0.393761  \n",
       "17     0.397214  \n",
       "18     0.391504  \n",
       "19     0.393728  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: model_output/imbalance_model_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Part 8: Train/eval loop with resampling and threshold tuning\n",
    "def evaluate_pipeline(model_name, sampler_name, sampler, verbose=False):\n",
    "    \"\"\"Build pipeline: Preprocess -> (Sampler?) -> Model, tune threshold on val, then test.\"\"\"\n",
    "    # Build steps\n",
    "    steps = [(\"preprocessor\", preprocessor)]\n",
    "    if sampler is not None:\n",
    "        steps.append((\"sampler\", sampler))\n",
    "    steps.append((\"clf\", build_model(model_name)))\n",
    "    \n",
    "    pipe = ImbPipeline(steps=steps)\n",
    "\n",
    "    # Fit on train only\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Validation probabilities for threshold selection\n",
    "    proba_val = pipe.predict_proba(X_val)[:, 1]\n",
    "    thr, best_val_f1 = pick_best_threshold(y_val, proba_val)\n",
    "\n",
    "    # Evaluate on test at tuned threshold\n",
    "    proba_test = pipe.predict_proba(X_test)[:, 1]\n",
    "    preds_test = (proba_test >= thr).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": model_name,\n",
    "        \"sampler\": sampler_name,\n",
    "        \"thr_val_best_f1\": thr,\n",
    "        \"val_best_f1\": best_val_f1,\n",
    "        \"test_accuracy\": accuracy_score(y_test, preds_test),\n",
    "        \"test_precision\": precision_score(y_test, preds_test, zero_division=0),\n",
    "        \"test_recall\": recall_score(y_test, preds_test, zero_division=0),\n",
    "        \"test_f1\": f1_score(y_test, preds_test, zero_division=0),\n",
    "        \"test_roc_auc\": roc_auc_score(y_test, proba_test),\n",
    "        \"test_pr_auc\": average_precision_score(y_test, proba_test)\n",
    "    }\n",
    "    if verbose:\n",
    "        print(f\"[{model_name} | {sampler_name}] ->\", {k: round(v,4) if isinstance(v, float) else v for k,v in metrics.items()})\n",
    "    return metrics, pipe\n",
    "\n",
    "all_results = []\n",
    "best_pipelines = {}  # (model_name, sampler_name) -> fitted pipeline\n",
    "\n",
    "for sampler_name, sampler in samplers_with_none.items():\n",
    "    print(f\"\\n=== Resampling: {sampler_name} ===\")\n",
    "    for model_name in model_names:\n",
    "        res, pipe = evaluate_pipeline(model_name, sampler_name, sampler, verbose=True)\n",
    "        all_results.append(res)\n",
    "        best_pipelines[(model_name, sampler_name)] = pipe\n",
    "\n",
    "results_df = pd.DataFrame(all_results).sort_values([\"model\", \"test_f1\"], ascending=[True, False]).reset_index(drop=True)\n",
    "display(results_df.head(20))\n",
    "\n",
    "results_csv = Path(OUTPUT_DIR) / \"imbalance_model_results.csv\"\n",
    "results_df.to_csv(results_csv, index=False)\n",
    "print(\"Saved results to:\", results_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d02967c-0c73-437a-a96c-418fe465eacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Use your LightGBM best pipeline or model\n",
    "# If you used the unified pipeline approach:\n",
    "pipe = best_pipelines[(\"LightGBM\", \"None\")]  # or whichever sampler performed best\n",
    "y_score = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute PR curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "avg_prec = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recall, precision, color=\"blue\", lw=2, label=f\"PR curve (AP={avg_prec:.3f})\")\n",
    "\n",
    "# Plot F1 iso-lines for visual reference\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = (f_score * x) / (2 * x - f_score)\n",
    "    y[y > 1] = np.nan\n",
    "    plt.plot(x, y, color=\"gray\", alpha=0.2)\n",
    "    plt.text(0.9, (f_score * 0.9) / (2 * 0.9 - f_score), f\"F1={f_score:.1f}\", fontsize=9)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"PrecisionRecall Curve for LightGBM\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf1693fb-7560-4085-adf3-a97f6c2c0d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Param combos: 10\n",
      "\n",
      "=== Fit 1/10: {'scale_pos_weight': 4.0, 'learning_rate': 0.02, 'num_leaves': 31, 'max_depth': 7, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'n_estimators': 5000, 'boosting_type': 'gbdt', 'random_state': 42, 'n_jobs': 1} ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_proc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m clf \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp)\n\u001b[1;32m     90\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     91\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m---> 92\u001b[0m     X_train_proc, y_train,\n\u001b[1;32m     93\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(X_val_proc, y_val)],\n\u001b[1;32m     94\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage_precision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     95\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m     96\u001b[0m )\n\u001b[1;32m     97\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Validation probabilities\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_proc' is not defined"
     ]
    }
   ],
   "source": [
    "# Part 8: LightGBM  imbalance fixes + threshold tuning (val-based)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    average_precision_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def compute_metrics(y_true, proba, threshold=0.5, prefix=\"\"):\n",
    "    preds = (proba >= threshold).astype(int)\n",
    "    out = {\n",
    "        f\"{prefix}threshold\": float(threshold),\n",
    "        f\"{prefix}accuracy\": accuracy_score(y_true, preds),\n",
    "        f\"{prefix}precision\": precision_score(y_true, preds, zero_division=0),\n",
    "        f\"{prefix}recall\": recall_score(y_true, preds, zero_division=0),\n",
    "        f\"{prefix}f1\": f1_score(y_true, preds, zero_division=0),\n",
    "        f\"{prefix}roc_auc\": roc_auc_score(y_true, proba),\n",
    "        f\"{prefix}pr_auc\": average_precision_score(y_true, proba),\n",
    "        f\"{prefix}positive_rate_pred\": float(preds.mean()),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def tune_threshold_for_f1(y_true, proba, grid=None):\n",
    "    if grid is None:\n",
    "        # try a dense grid in the range that usually helps for ~1020% positives\n",
    "        grid = np.linspace(0.05, 0.5, 46)  # 0.05, 0.06, ..., 0.50\n",
    "    best_t, best_f1 = 0.5, -1.0\n",
    "    for t in grid:\n",
    "        f1 = f1_score(y_true, (proba >= t).astype(int), zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, float(t)\n",
    "    return best_t, best_f1\n",
    "\n",
    "def plot_curves(y_true, proba, name_prefix):\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, proba)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={roc_auc_score(y_true, proba):.3f}\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\"); plt.title(f\"ROC  {name_prefix}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    roc_path = os.path.join(OUTPUT_DIR, f\"{name_prefix}_ROC.png\")\n",
    "    plt.savefig(roc_path, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "    # PR\n",
    "    prec, rec, _ = precision_recall_curve(y_true, proba)\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec, label=f\"AP={average_precision_score(y_true, proba):.3f}\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"Precision-Recall  {name_prefix}\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    pr_path = os.path.join(OUTPUT_DIR, f\"{name_prefix}_PR.png\")\n",
    "    plt.savefig(pr_path, bbox_inches=\"tight\"); plt.close()\n",
    "    return {\"roc_plot\": roc_path, \"pr_plot\": pr_path}\n",
    "\n",
    "# ---------- small param sweep ----------\n",
    "param_grid = []\n",
    "for w in [4.0, 5.0, 6.0, 7.0, 8.0]:       # imbalance strength\n",
    "    for lr in [0.02, 0.03]:               # learn slower, train longer\n",
    "        param_grid.append({\n",
    "            \"scale_pos_weight\": w,\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_leaves\": 31,\n",
    "            \"max_depth\": 7,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"reg_alpha\": 0.1,\n",
    "            \"reg_lambda\": 0.1,\n",
    "            \"n_estimators\": 5000,\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"random_state\": RANDOM_STATE,\n",
    "            \"n_jobs\": 1\n",
    "        })\n",
    "\n",
    "val_results = []\n",
    "best_record = None\n",
    "\n",
    "print(f\"[INFO] Param combos: {len(param_grid)}\")\n",
    "for i, p in enumerate(param_grid, 1):\n",
    "    print(f\"\\n=== Fit {i}/{len(param_grid)}: {p} ===\")\n",
    "    clf = lgb.LGBMClassifier(**p)\n",
    "    start = time.time()\n",
    "    clf.fit(\n",
    "        X_train_proc, y_train,\n",
    "        eval_set=[(X_val_proc, y_val)],\n",
    "        eval_metric=[\"auc\", \"average_precision\"],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)]\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    # Validation probabilities\n",
    "    val_proba = clf.predict_proba(X_val_proc)[:, 1]\n",
    "\n",
    "    # Metrics at default 0.5\n",
    "    val_metrics_05 = compute_metrics(y_val, val_proba, threshold=0.5, prefix=\"val@0.5_\")\n",
    "\n",
    "    # Tune threshold for F1 on validation\n",
    "    best_t, best_f1 = tune_threshold_for_f1(y_val, val_proba)\n",
    "    val_metrics_best = compute_metrics(y_val, val_proba, threshold=best_t, prefix=\"val@best_\")\n",
    "\n",
    "    # Keep record\n",
    "    record = {\n",
    "        \"params\": p,\n",
    "        \"best_iteration\": int(getattr(clf, \"best_iteration_\", p[\"n_estimators\"]) or p[\"n_estimators\"]),\n",
    "        \"train_time_sec\": round(train_time, 3),\n",
    "        **val_metrics_05,\n",
    "        **val_metrics_best,\n",
    "        \"val_best_threshold\": best_t\n",
    "    }\n",
    "    val_results.append(record)\n",
    "\n",
    "    # Track best by F1 on validation (tie-break by PR-AUC)\n",
    "    if (best_record is None) or \\\n",
    "       (record[\"val@best_f1\"] > best_record[\"val@best_f1\"]) or \\\n",
    "       (np.isclose(record[\"val@best_f1\"], best_record[\"val@best_f1\"]) and\n",
    "        record[\"val@best_pr_auc\"] > best_record[\"val@best_pr_auc\"]):\n",
    "        best_record = record\n",
    "        best_model = clf\n",
    "\n",
    "print(\"\\n[SUMMARY] Validation sweep (top 5 by F1):\")\n",
    "df_val = pd.DataFrame(val_results).sort_values(\"val@best_f1\", ascending=False)\n",
    "display(df_val.head(5))\n",
    "\n",
    "# Save sweep table\n",
    "val_csv = os.path.join(OUTPUT_DIR, \"lgbm_val_sweep.csv\")\n",
    "df_val.to_csv(val_csv, index=False)\n",
    "print(\"Saved:\", val_csv)\n",
    "\n",
    "print(\"\\n[WINNER] Best validation config:\")\n",
    "pprint({k: best_record[k] for k in [\n",
    "    \"val@best_f1\",\"val@best_precision\",\"val@best_recall\",\"val@best_pr_auc\",\"val@best_roc_auc\",\"val_best_threshold\",\n",
    "    \"val@0.5_f1\",\"val@0.5_precision\",\"val@0.5_recall\",\"val@0.5_pr_auc\",\"best_iteration\",\"train_time_sec\"\n",
    "]})\n",
    "print(\"\\nBest params:\")\n",
    "pprint(best_record[\"params\"])\n",
    "\n",
    "# Plots on validation for the best model\n",
    "val_plots = plot_curves(y_val, best_model.predict_proba(X_val_proc)[:,1], \"LightGBM_val_best\")\n",
    "print(\"Validation plots saved:\", val_plots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6d3c7-fa89-4bf7-8051-c2fd95c18576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 10: Inspect best per model by test F1 and show top importances for tree boosters\n",
    "best_rows = results_df.sort_values(\"test_f1\", ascending=False).groupby(\"model\", as_index=False).first()\n",
    "display(best_rows[[\"model\",\"sampler\",\"thr_val_best_f1\",\"test_f1\",\"test_precision\",\"test_recall\",\"test_pr_auc\",\"test_roc_auc\"]])\n",
    "\n",
    "def show_top_importances(model_name, sampler_name, top_k=15):\n",
    "    pipe = best_pipelines[(model_name, sampler_name)]\n",
    "    clf = pipe.named_steps[\"clf\"]\n",
    "    # Get feature names post-preprocessing\n",
    "    feat_names_num = [f\"num__{c}\" for c in numeric_cols]\n",
    "    feat_names_bin = binary_cols[:]  # passthrough keeps original names\n",
    "    feature_names = feat_names_num + feat_names_bin\n",
    "\n",
    "    importances = None\n",
    "    if hasattr(clf, \"feature_importances_\"):\n",
    "        importances = clf.feature_importances_\n",
    "    elif hasattr(clf, \"coef_\"):\n",
    "        # Logistic regression (absolute coefficients)\n",
    "        coef = np.ravel(clf.coef_)\n",
    "        importances = np.abs(coef)\n",
    "    else:\n",
    "        print(f\"No importances available for {model_name}.\")\n",
    "        return\n",
    "\n",
    "    imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances}).sort_values(\"importance\", ascending=False).head(top_k)\n",
    "    display(imp_df)\n",
    "\n",
    "# Example: show importances for your best LightGBM variant if it appears in best_rows\n",
    "for _, row in best_rows.iterrows():\n",
    "    if row[\"model\"] in [\"LightGBM\",\"RandomForest\",\"XGBoost\",\"LogisticRegression\"]:\n",
    "        print(f\"\\nTop features for {row['model']} ({row['sampler']}):\")\n",
    "        show_top_importances(row[\"model\"], row[\"sampler\"], top_k=15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
